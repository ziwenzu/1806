{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pset 3 (spring 2020 revised 8pm) <br>\n",
    "(Optional: if you wish to download this notebook as an .ipynb file, use the download button in the upper right and OPTION-click (MAC) or ALT-Click (Linux and Windows ) then \"Save Link as..\" or \"Download Linked File As..\" or something similar on your browser.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1. Let x̄$\\ = \\frac{1}{n}\\sum_{i=1}^n x_i$ denote the mean of x. What is \n",
    "sum( x.-x̄).  (Remember that x.-x̄ is the vector x with an elementwise subtraction of x̄). Explain your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to try some examples in Julia (optional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.220446049250313e-16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Statistics\n",
    "n = 8 \n",
    "x = rand(n)\n",
    "x̄ = mean(x)\n",
    "sum( x .- x̄)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution 1. The sum is zero, as it is equal to $\\sum_{i=1}^n(x_i-x̄)=\\sum_{i=1}^n(x_i)-nx̄=n\\sum_{i=1}^n(\\frac{x_i}{n})-nx̄=nx̄-nx̄=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2.  (We may supply some hints as we go, so check back in ) <br>\n",
    "This problem shows how the QR idea can derive the formulas for best fit lines. <br>\n",
    "a)Suppose (xᵢ,yᵢ) for i=1,...m are data which we will fit with a best least squares line.  Let\n",
    "a = x .- x̄ and b = y .- ȳ. <br> The slope of the best line through the (aᵢ,bᵢ) is 1) the same  2) bigger 3) smaller\n",
    "than the line through the (xᵢ,yᵢ) for i=1,...m ?  Explain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) In terms of a and b, write an m x 2 matrix A  and a right hand side expressing $A [slope; intercept] = $ right hand side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) What is the dot product of the first columns of A with the second?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Use the result in c to derive the QR factorization of $A$ without too much hard work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) What is the slope of the best least squares line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) The intercept is very simple?  Why is this result obvious?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) What are the slope and intercept for the original data (xᵢ,yᵢ) without any hard work?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution 2. a) 1) The same. After the translation of $(-x̄,-ȳ)$, the best fit line for $(x_i,y_i)$ coincide with that for $(a_i,b_i)$. This is because parallel translation preserves the distance between points and lines, which implies the error function of points with respect to a line is the same as that after translation. \n",
    "\n",
    "b) $\\begin{pmatrix} a_1 & 1 \\\\ a_2 & 1 \\\\ \\vdots & \\vdots \\\\ a_m & 1 \\end{pmatrix}\\begin{pmatrix} slope \\\\ intercept \\end{pmatrix} \\approx \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{pmatrix}$\n",
    "\n",
    "c) $0$, by Problem 1. \n",
    "\n",
    "d) $\\begin{pmatrix} a_1 & 1 \\\\ a_2 & 1 \\\\ \\vdots & \\vdots \\\\ a_m & 1 \\end{pmatrix}=\\begin{pmatrix} a_1 / \\|a\\| & 1/ \\sqrt{m} \\\\ a_2/\\|a\\| & 1/ \\sqrt{m} \\\\ \\vdots & \\vdots \\\\ a_m/\\|a\\| & 1/ \\sqrt{m} \\end{pmatrix}\\begin{pmatrix} \\|a\\| & 0 \\\\ 0 & \\sqrt{m} \\end{pmatrix}$\n",
    "\n",
    "e)  $slope= [1 \\ 0 ]R^{-1}Q^T b$ = $(1 / \\|a\\|) [1 \\ 0] Q^Tb = (a^Tb)/\\|a\\|^2$ which can be recognized as a formula for β̂ in the [simple linear regression formula in wikipedia](https://en.wikipedia.org/wiki/Simple_linear_regression#Intuitive_explanation). \n",
    "\n",
    "f) We can expect that if we remove the mean, the data should go through (0,0) that is the intercept is 0. One can also directly look at the second element of $Q^Tb$ which is readily seen to be 0 because of the solution to problem 1.\n",
    "\n",
    "g) We expect the line to shift from $(0,0)$ to $(x̄,ȳ)$.\n",
    "\n",
    "\n",
    "Part (a) and (e) tell us that the slope is $\\frac{\\sum_{i=1}^ma_ib_i}{\\sum_{i=1}^ma_i^2}$. \n",
    "We then have y = (slope)x + intercept, and we expect $(x̄,ȳ)$ on the line, \n",
    "so the intercept has to be $ȳ-\\frac{\\sum_{i=1}^ma_ib_i}{\\sum_{i=1}^ma_i^2}x̄$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3.  Suppose A=QR is square, where Q is orthogonal and R is upper triangular and invertible. Write the solution to Ax=b in terms of b and possibly Q,Qᵀ,and R.\n",
    "\n",
    "Solution 3. $x=R^{-1}Q^Tb$ because $x=A^{-1}b=(QR)^{-1}b=R^{-1}Q^{-1}b=R^{-1}Q^Tb$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4. Set up a matrix least squares problem if we are interested in taking n data points $(x_i,y_i)$ and we wish to find the best function f(x)=$c_1e^x+c_2e^{−x}$  through the data points.\n",
    "\n",
    "Solution 4. \n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "e^{x_1} & e^{-x_1} \\\\\n",
    "e^{x_2} & e^{-x_2} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "e^{x_n} & e^{-x_n}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "c_1 \\\\\n",
    "c_2\n",
    "\\end{pmatrix}\n",
    "\\approx\n",
    "\\begin{pmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 5. Find $A^T$ and $A^{-1}$ and $(A^{-1})^T$ and $(A^T)^{-1}$ for\n",
    "$A=\\left( \\begin{matrix} 1 & 0 \\\\ 9 & 3 \\end{matrix}\\right)$.\n",
    "\n",
    "Solution 5. $A^T=\\begin{pmatrix} 1 & 9 \\\\ 0 & 3\\end{pmatrix}$ , $A^{-1}= \\begin{pmatrix} 1 & 0 \\\\ -3 & 1/3 \\end{pmatrix}$, $(A^{-1})^T= (A^T)^{-1} = \\begin{pmatrix} 1 & -3 \\\\ 0 & 1/3 \\end{pmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6. A matrix $A$ is symmetric if $A=A^T$.  Which of these are true if A is symmetric?  <br>\n",
    "6a. The block matrix $\\begin{pmatrix} 0  & A\\\\ A  & 0 \\end{pmatrix}$ is automatically symmetric. <br>\n",
    "6b. If A and B are symmetric then their product AB is symmetric. <br>\n",
    "6c. If A is not symmetric then $A^{−1}$ is not symmetric. <br>\n",
    "6d. When A,B,C are symmetric, the transpose of ABC is CBA <br>\n",
    "If $A=A^T$ and $B=B^T$, which of these matrices are certainly symmetric? <br>\n",
    "6e. $A^2−B^2$ <br>\n",
    "6f. $(A+B)(A−B)$<br>\n",
    "6g. $ABA$<br>\n",
    "6h.  $ABAB$<br>\n",
    "\n",
    "Solution 6.  <br>\n",
    "\n",
    "6a.  True if you assume $A$ is symmetric. False otherwise. The wording of the problem left this\n",
    "unclear, so either answer could be \"right.\" The block matrix is symmetric because the transpose of the block is\n",
    "$\\begin{pmatrix} 0  & A^T\\\\ A^T  & 0 \\end{pmatrix}$ =\n",
    "$\\begin{pmatrix} 0  & A\\\\ A & 0 \\end{pmatrix}$ if you assume $A$ is symmetric.\n",
    "Otherwise the block would not be symmetric.<br>\n",
    "6b. False. No, it is easy to construct counterexamples. <br>\n",
    "6c.\n",
    "True. \"If A is not symmetric then $A^{−1}$ is not symmetric\".\n",
    "Logically this is equivalent to if $A^{−1}$ is symmetric then so is $A$ or even\n",
    "if $A$ is symmetric and invertible, so is $A^{-1}$.  If $A$ is symmetric, one can tranpose $AA^{-1}=I$\n",
    "to obtain $(A^{-1})^TA^T=I = (A^{-1})^TA$ showing A $A^{-1}=(A^{-1})^T$ which means $A^{-1}$ is symmetric.\n",
    "\n",
    "<br> 6d \"When A,B,C is symmetric, the transpose of ABC is CBA is true by taking transposes. <br>\n",
    "6e) $A^2−B^2$ and 6g)$ABA$ must be symmetric by taking transposes. Taking $A=\\begin{pmatrix} 1  & 1\\\\ 1  & 0 \\end{pmatrix}$ and $B= \\begin{pmatrix} 1  & 1\\\\ 1  & 1 \\end{pmatrix}$ provides non-symmetric examples in 6f and 6h. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 7 (GS p.106 13)\n",
    "Compute U and L for the symmetric matrix A:  <br>\n",
    "$\\left( \\begin{matrix}\n",
    "a & a  & a & a \\\\\n",
    "a & b  & b & b \\\\\n",
    "a & b  & c & c \\\\\n",
    "a & b  & c &  d\n",
    "\\end{matrix} \\right) $.\n",
    "Find four conditions on a,b,c,d to get A=LU with four pivots.\n",
    "\n",
    "Solution 7. $\\begin{pmatrix}\n",
    "a & a  & a & a \\\\\n",
    "a & b  & b & b \\\\\n",
    "a & b  & c & c \\\\\n",
    "a & b  & c & d \\end{pmatrix}=\\begin{pmatrix}\n",
    "1 & 0  & 0 & 0 \\\\\n",
    "1 & 1  & 0 & 0 \\\\\n",
    "1 & 0  & 1 & 0 \\\\\n",
    "1 & 0  & 0 & 1\n",
    "\\end{pmatrix}\\begin{pmatrix}\n",
    "1 & 0  & 0 & 0 \\\\\n",
    "0 & 1  & 0 & 0 \\\\\n",
    "0 & 1  & 1 & 0 \\\\\n",
    "0 & 1  & 0 & 1\n",
    "\\end{pmatrix}\\begin{pmatrix}\n",
    "1 & 0  & 0 & 0 \\\\\n",
    "0 & 1  & 0 & 0 \\\\\n",
    "0 & 0  & 1 & 0 \\\\\n",
    "0 & 0  & 1 & 1\n",
    "\\end{pmatrix}\\begin{pmatrix}\n",
    "a & a  & a & a \\\\\n",
    "0 & b-a  & b-a & b-a \\\\\n",
    "0 & 0  & c-b & c-b \\\\\n",
    "0 & 0  & 0 & d-c\n",
    "\\end{pmatrix}$. Hence $\\begin{pmatrix}\n",
    "a & a  & a & a \\\\\n",
    "a & b  & b & b \\\\\n",
    "a & b  & c & c \\\\\n",
    "a & b  & c & d \\end{pmatrix}=\\begin{pmatrix}\n",
    "1 & 0  & 0 & 0 \\\\\n",
    "1 & 1  & 0 & 0 \\\\\n",
    "1 & 1  & 1 & 0 \\\\\n",
    "1 & 1  & 1 & 1\n",
    "\\end{pmatrix}\\begin{pmatrix}\n",
    "a & a  & a & a \\\\\n",
    "0 & b-a  & b-a & b-a \\\\\n",
    "0 & 0  & c-b & c-b \\\\\n",
    "0 & 0  & 0 & d-c\n",
    "\\end{pmatrix}$ is the LU factorization. $A$ has four pivot if and only if $a,b-a,c-b,d-c$ are non-zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 8.  First computation of a singular value decomposition. <br>\n",
    "\n",
    "\n",
    "Here we wish for you to become familiar with an SVD by changing the m and n from what appears here\n",
    "and testing that the results have the required properties.  You merely need to execute and turn in\n",
    "a screen shot. Describe in a few words what kind of matrix is U, V, and diagm(Σ) for your chosen m and n.\n",
    "Say sizes, and use words like orthogonal, tall skinny orthogonal, diagonal, triangular etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One version of the SVD produces $$ A = U * Diagonal(\\Sigma) * V',$$ where  $U'U=I$, $V'V=I$, $\\Sigma=(\\sigma_1,\\sigma_2,...)$ with $\\sigma_1 \\ge \\sigma_2 \\ge ... \\gt 0$.  <br>\n",
    "$U$ is $m \\times n$ and $V$ is $n \\times n$ if $ m \\ge n$, and \n",
    "$U$ is $m \\times m$ and $V$ is $n \\times m$ if $ m \\lt n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 2.0908607204660132\n",
       " 0.5438073613767322\n",
       " 0.1985541583756679"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "A = rand(5,3)\n",
    "U,Σ,V = svd(A)\n",
    "display(Σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U'U ≈ I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V'V ≈ I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A ≈ U * diagm(Σ) * V'\n",
    "A ≈ U * Diagonal(Σ) * V'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution 8. The following answer depends on the choice of $m$ and $n$. \n",
    "First case is when $m > n$, (e.g. $A$ is a $5 \\times 3$ matrix as mentioned above). $U$ is a tall skinny orthogonal matrix of size $m \\times n$; $Diagonal(\\Sigma)$ is a diagonal matrix of size $n \\times n$ and $V$ is an orthogonal matrix of size $n \\times n$. \n",
    "\n",
    "Second case is when $m < n$. $U$ is an orthogonal matrix of size $m \\times m$; $Diagonal(\\Sigma)$ is a diagonal matrix of size $m \\times m$ and $V$ is a tall skinny orthogonal matrix of size $n \\times m$.\n",
    "\n",
    "Third case is when $m=n$. $U$ is an orthogonal matrix of size $m \\times m$; $Diagonal(\\Sigma)$ is a diagonal matrix of size $m \\times m$ and $V$ is an orthogonal matrix of size $m \\times m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 9. Suppose a square $A$ has an LU factorization $A=LU$ where $L$ and $U$ are invertible. If $A=QR$, what is $r_{11}$ in terms of possibly elements of $L$ and $U$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution 9. $r_{11}=U_{11} \\sqrt{\\sum_i L_{i1}^2}$. We know that $r_{11}$ is the norm of first column vector of $A$, which is equal to $U_{11}$ times the first column vector of $L$.   (technically it could be $\\pm$ the above answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 10 .  Suppose an n x 2 matrix $A$ is written as $QR$, where $Q$ is a tall-skinny orthogonal matrix and is also n x 2 and R = $ \\left( \\begin{matrix} 1 & 3 \\\\ 0 & 4 \\end{matrix} \\right)  $<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the norm of the second column of $A$? Briefly explain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution 10. Its norm is $5$.  Since $A^TA=R^TQ^TQR=R^TR$, it is true that the norm of every column of $A$ is the norm of the corresponding column of $R$ and also dot products of columns of $A$ are that of $R$ as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
