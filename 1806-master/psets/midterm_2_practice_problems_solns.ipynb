{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions to midterm 2 practice problems - DRAFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "1a) Under what size conditions does Trace(AB) = Trace(BA)? <br>\n",
    "1b) Under what size conditions does Trace(ABC) = Trace(BCA)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "1a) This formula holds provided that $AB$ and $BA$ are both valid matrix products. If $A$ is $m\\times n$, then this necessarily requires that $B$ is $n\\times m$.<br>\n",
    "\n",
    "1b) This formula holds provided that $A(BC)$ and $(BC)A$ are both valid matrix products. If $A$ is $m\\times n$, then this necessarily requires that $BC$ is $n\\times m$. In turn, this means that $B$ is $n\\times p$ and $C$ is $p\\times m$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "2a. Find a basis for all polynomials of the form $a+bx+cx^2+dx^3$ whose integral on $[0,1]$ is 0. <br>\n",
    "2b. Find a basis for all polynomials that are a derivative of polynomials of the form $a+bx+cx^2+dx^3$ <br>\n",
    "2c. Find a basis for all polynomials that are of the form  $a+b(x+1)+c(x+1)^2+d(x+1)^3$ <br>\n",
    "2d. Find a basis for all polynomials of the form $a+bx+cx^2+dx^3$ whose value at 1 is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "2a. We firstly find that \n",
    "$$\\int_0^1 (a+bx+cx^2 +dx^3) dx = 0 \\implies a+b/2+c/3+d/4 = 0.$$\n",
    "Notice that we are only free to select three of the coefficients of such a polynomial; the fourth coefficient will be uniquely selected by the requirement that the polynomial integrates to 0. These polynomials form a three dimensional vector space. A possible basis is then the set $\\{1-4x^3,2x-4x^3,3x^2-4x^3\\}$. This is certainly linearly independent, and by construction it spans this subspace of polynomials.<br>\n",
    "\n",
    "2b. The derivative of a cubic polynomial $a+bx+cx^2+dx^3$ is $b + 2cx+3dx^2$, i.e. a quadratic. Polynomials of degree at most two are a three dimensional vector space with basis $\\{1,x,x^2\\}$. <br>\n",
    "\n",
    "2c. Polynomials of this form are just cubics that have been shifted to the left. A possible basis is $\\{1,(x+1),(x+1)^2,(x+1)^3\\}$. Another possible basis is just the standard basis $\\{1,x,x^2,x^3\\}$.<br>\n",
    "\n",
    "2d. The restriction that these polynomials vanish at $x=1$ requires that $a+b+c+d = 0$. Such polynomials will form a three dimensional vector subspace, with a possible basis being $\\{1-x^3,x-x^3,x^2-x^3\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "(3). How many parameters are needed to specify a linear transformation from 10x10x10 arrays to $R^2$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "To uniquely specify a linear transformation between two vector spaces, we need to know how the linear transformation acts on any basis for the input vector space. The space of $10\\times 10 \\times 10$ arrays is a $10^3$ dimensional vector space, so we need to know how the linear transformation acts on each of the $10^3$ basis elements in some basis. Since the linear transformation outputs vectors in $\\mathbb{R}^2$, we will need two parameters for each of the basis elements in the input space. This means we will need a total of $\\boxed{2\\times 10^3}$ parameters to specify this linear transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "(4). Compute the gradient of $f(x)=x^Tx  + sum(x) $ without the use of indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution \n",
    "\n",
    "We can compute the gradient of $f(x)$ by evaluating $f(x+dx)$:\n",
    "\\begin{align*}\n",
    "f(x+dx) &= (x+dx)^T(x+dx)  + sum(x+dx) \\\\\n",
    "&= x^Tx + 2x^T dx + dx^Tdx + sum(x) + sum(dx)\\\\\n",
    "&= f(x) + \\left(2x^T + \\begin{pmatrix} 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix}^T\\right) dx +...\n",
    "\\end{align*}\n",
    "We can therefore identify that\n",
    "$$\\boxed{\\nabla f = 2x + \\begin{pmatrix} 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "(5a). Remembering that df(x) = f'(x) dx for scalar functions, what is dh.(A) in terms of f'.(A) and dA?\n",
    "(Here the dot denotes elementwise function application and A is a matrix.)  <br>\n",
    "(5b). (Challenging?) If g(A) = h.(A*x -b), where x and b are held fixed, h is a scalar function, compute dg in terms of dA.  This is \n",
    "a linear transformation from the matrix dA to the vector dg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "(a) Let $h$ be an arbitrary, differentiable scalar function. $h.A$ is a matrix obtained by apply $h$ to each of the components of $A$. Now the $ij$-th component of $h.(A+dA)$ is $h(A_{ij}+dA_{ij})$, and \n",
    "$$h(A_{ij}+dA_{ij}) = h(A_{ij})+h'(A_{ij})dA_{ij}.$$\n",
    "The $ij$-th component of $dh.A$ is therefore $h'(A_{ij})dA_{ij}$, and so\n",
    "$$dh.A = (h'.A).*dA$$ <br>\n",
    "\n",
    "(b) Let B = Ax - b. Then the above implies that \n",
    "$$dg.A = (h'.B).*dB = (h'.(Ax-b)).*(dA x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "(6). True or false: <br>\n",
    "a) det(2A) = 2 det(A) for all n <br>\n",
    "b) det(-A) = -det(A) if the size n is odd <br>\n",
    "c) det(A+B) = det(A) + det(B) since determinants are multilinear <br>\n",
    "d) det(inv(A)) = 1/det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "a) False. The determinant of a diagonal matrix is the product of the entries along the diagonal. The determinant of the $3\\times 3$ identity matrix $I_3$ is therefore 1, but the determinant of $2I_3$ is $2^3 = 8$, for example. <br>\n",
    "\n",
    "b) This is true. The determinant is linear in each row. Multiplying a matrix $A$ by $-1$ is equivalent to multiplying each row by $-1$. We will therefore have that $\\det(-A) = (-)^n \\det (A)$, and so the result holds for all odd $n$.\n",
    "\n",
    "c) This is false. For example:\n",
    "$$A = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}, \\;\\; B = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix}$$\n",
    "Then $\\vert A \\vert = \\vert B \\vert = 0$, but $A+B = I_2$, and $\\det(I_2) = 1$. \n",
    "\n",
    "d) True. We know that $\\det(AB)=\\det(A)\\det(B)$. We also know that $\\det(I) = 1$, where $I$ is the $n\\times n$ identity matrix. Therefore \n",
    "$$1 = \\det(I) = \\det(A^{-1} A) = \\det(A^{-1})\\det(A)$$\n",
    "and so \n",
    "$$\\boxed{\\det(A^{-1}) = 1/\\det(A)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "\n",
    "(7). Give an example of a matrix A where the rows of A are not a basis for the rowspace.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution \n",
    "\n",
    "Any example where the rows are not linearly independent will work. For example,\n",
    "$$A = \\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8\n",
    "\n",
    "(8). Suppose we have  ùê¥=[ùë¢ v ùë§][ ùë• y z]ùëá  without any assumptions whatsoever on the vectors u,v,w,x,y,z other than is required by block notation. <br>\n",
    "(A) What are the possible ranks of  ùê¥  assuming  ùê¥  is  ùëö√óùëõ ?  <br>\n",
    "(B) Under what conditions is the rank of  ùê¥  3? <br>\n",
    "(C) Under what conditions is the rank of  ùê¥  1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution \n",
    "\n",
    "(a) $A$ can have rank less than or equal to 3.<br>\n",
    "\n",
    "(b) In order for $A$ to be rank 3, the vectors $u,v,w$ must all be linearly independent and so must $x,y,z$.<br>\n",
    "\n",
    "(c) In order for $A$ to be rank 1, either the vectors $u,v,w$ must be collinear, or the vectors $x,y,z$ must be collinear, or both. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9\n",
    "\n",
    "(9). Suppose we are given the full SVD of an mxn matrix A on a computer. <br>\n",
    "9a. How would you obtain the rank r? <br>\n",
    "9b. How would you check if $A^TA$ is invertible? <br>\n",
    "9c. How would you check, given a vector $b$, if $Ax=b$ has a solution? <br>\n",
    "9d. If Ax=b has at least one solution, how would you obtain the solution $x$? <br>\n",
    "9e. What is the complete solution to Ax=b, assuming at least one solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution \n",
    "\n",
    "a) The rank $r$ is the number of non zero singular values.<br>\n",
    "b) $A^TA$ is invertible provided that the rank is equal to the number of columns in $A$.<br>\n",
    "c) $Ax = b$ has a solution provided that $U_1U_1^T b = b$, where $A=U\\Sigma V^T$.<br>\n",
    "d) If $Ax =b$ is solvable, then $x = V_1\\Sigma_r^{-1} U_1^T b$ is always a solution.<br>\n",
    "e) Let $x_0$ be any particular solution, and let $y_1, ... y_{n-r}$ be the last $n-r$ vectors of $V$ (which are a basis for $N(A)$). Then the complete solution is \n",
    "$$x = x_0 + c_1 y_1 + c_2y_2+...+c_{n-r} y_{n-r}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10\n",
    "\n",
    "(10).  Suppose you have two non-colinear vectors in $\\mathbb{R}^3$.  How might you use the full svd to compute the cross product of these two vectors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution \n",
    "\n",
    "Consider two non-colinear vectors $a$ and $b$ in $\\mathbb{R}^3$. Let $u = a\\times b$. In particular, $u$ is mutually orthogonal to both $a$ and $b$. If we let $A$ be a matrix whose columns are the vectors $a$ and $b$, we can then compute the full svd $A=U\\Sigma V^T$. The third column of $U$ is then a basis for $N(A^T)$, which is orthogonoal to $C(A)$. Therefore the third column of $u$ is orthogonal to both $a$ and $b$, and is therefore in the same direction as $u=a\\times b$.\n",
    "\n",
    "We are almost ready in our class to figure\n",
    " out the magnitude of the cross product. It is exactly $\\sigma_1 \\sigma_2$. If $U\\Sigma V^T$ is the compact svd with $U$ 3x2, then\n",
    "$\\Sigma V^T$ describes the same parallelogram, and its determinant is the area. \n",
    "\n",
    "The sign is always tricky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 11\n",
    "\n",
    "Remember that the determinant of a product of square matrices is the product of the determinants. <br>\n",
    "(11a.) Use Q'Q=I to show that det(Q)=¬±1 for an orthogonal matrix Q. <br>\n",
    "(11b.)  Show that det(A) is ¬±(the product of the n singular values) assuming $A$ is non-singular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "(a) We can prove this as follows:\n",
    "\\begin{align*}\n",
    "Q^TQ = I &\\implies \\det(Q^TQ) = 1\\\\\n",
    "        &\\implies \\det(Q^T)\\det(Q) = 1\\\\\n",
    "        &\\implies (\\det(Q))^2 = 1\\\\\n",
    "        &\\implies \\det(Q) = \\pm 1.\n",
    "\\end{align*}\n",
    "\n",
    "(b) Let $A = U\\Sigma V^T$ be the compact svd for $A$. Then $U$ and $V$ are orthogonal matrices. Then \n",
    "$$\\det(A) = \\det(U\\Sigma V^T) = \\det(U)\\det(\\Sigma)\\det(V^T) = \\pm \\det(\\Sigma).$$\n",
    "But $\\Sigma$ is a diagonal matrix, and so its determinant is the product of its diagonal entries, i.e. the singular values. This means that det(A) is ¬±(the product of the n singular values). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 12\n",
    "\n",
    "(12). Describe how you can use the compact svd to obtain the projection matrix onto the column space of a matrix $A$? Are there any conditions on A?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "To project onto the column space of $A=U \\Sigma V^T$, we recall that the columns of $U$ in the compact svd are an orthonormal basis for $C(A)$. Therefore the matrix $UU^T$ is always a projection matrix onto the column space of $A$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 13\n",
    "\n",
    "(13). Describe the solution to the least squares problem Ax‚âàb when b is not necessasrily in the column space of A in terms of the compact SVD.  You may assume that A has independent columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "The least squares solution to $Ax = b$ is given by the solution to the normal equations $A^TA\\hat{x}=A^Tb$. If $A$ has independent columns, then $A^TA$ is invertible. Let $A=U\\Sigma V^T$ be the compact svd for $A$. Then the least squares solution is\n",
    "\\begin{align*}\n",
    "\\hat{x} &= (A^TA)^{-1} A^T b\\\\\n",
    "        &= ((U\\Sigma V^T)^T U\\Sigma V^T)^{-1} (U\\Sigma V^T)^T b\\\\\n",
    "        &= (V\\Sigma^2 V^T)^{-1} V\\Sigma U^T b\\\\\n",
    "        &= V\\Sigma^{-2} V^TV\\Sigma U^T b\\\\\n",
    "    \\implies \\hat{x} &= V\\Sigma^{-1}U^T b.\n",
    "\\end{align*}\n",
    "\n",
    "The problem is now solved.  We could go further and compute $A\\hat{x}$ and see $A\\hat{x} = (U\\Sigma V^T) (V\\Sigma^{-1}U^T) b = UU^Tb$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 14\n",
    "\n",
    "(14). A vector space V has two bases: $b_1,b_2,b_3,b_4$ and $d_1,d_2,d_3,d_4$. <br>\n",
    "14a. What is the dimension of $V$? <br>\n",
    "14b. Suppose $[b_1,b_2,b_3,b_4] = [d_1,d_2,d_3,d_4] \\begin{pmatrix} 1 &&& \\\\ x &1&& \\\\ y &&1& \\\\ z &&& 1 \\end{pmatrix}$.  What is $d_1+d_2+d_3+d_4$ in terms of the b's?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution \n",
    "\n",
    "(a) $V$ has four elements in its bases, and so the dimension of $V$ is 4.\n",
    "(b) The given relationship between $b_1,b_2,b_3,b_4$ and $d_1,d_2,d_3,d_4$ tells us that $b_2=d_2$, $b_3=d_3$, $b_4=d_4$, and $b_1 = d_1+xd_2+yd_3+zd_4$. We can invert this fourth equation to deduce that \n",
    "$$d_1 = b_1 - xb_2-yb_3-zb_4.$$\n",
    "So finally we can write that\n",
    "$$\\boxed{d_1+d_2+d_3+d_4 = b_1+(1-x)b_2+(1-y)b_3 + (1-z)b_4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 15\n",
    "\n",
    "15) Let d(A) be a scalar function of 3 √ó 2 matrices A with the following properties: <br>\n",
    "Œ±) If you interchange the two columns of A, d(A) flips sign. <br>\n",
    "Œ≤) d(A) is linear in each of the columns of A. <br>\n",
    "Œ≥) d(A) is non-zero for at least one 3 √ó 2 A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(15a.)  What is d(2A) in terms of d(A)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(15b.) Give an example d(A) that satisfies the three requirements of this question <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(15c.) We recall that the determinant of square matrices is linear in each column and\n",
    "each row of the square matrix. Can property Œ≤ be extended to rows and columns of 3 √ó 2\n",
    "matrices A to create a d(A) with the three requirements of this question? If yes, give an\n",
    "example, if not, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(15d.) If we discard property Œ≥ to allow the ‚Äúzero‚Äù function, the set of all functions\n",
    "d(A) satisfying Œ± and Œ≤ form a three dimensional vector space. Describe explicitly this vector\n",
    "space of functions in terms of the elements of A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "This question appeared on last year's quiz 2 as problem 4. Parts c and d were considered challenging.\n",
    "\n",
    "The solutions are posted [here](https://web.mit.edu/18.06/www/Spring18/quiz2solutions.pdf).\n",
    "\n",
    "This problem was no doubt challenging for an exam though quite a few students solved it.\n",
    "\n",
    "A key fact is that if you take $A$ and augment it with $\\begin{pmatrix} c_1 \\\\ c_2 \\\\ c_3 \\end{pmatrix}$  then the determinant of the augmented matrix satisfies the required properties of the first two columns. This is true for any value of $c_1,c_2,c_3$.\n",
    "\n",
    "To show we have all solutions one can check that if set $c_3$ to be\n",
    "$D(\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\end{pmatrix})$, $c_2=-D(\\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\\\ 0 & 1 \\end{pmatrix})$ and\n",
    "$c_3=D(\\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\\\ 0 & 1 \\end{pmatrix})$, then\n",
    "one can derive that $D(A)$ is the determinant of the augmented matrix,\n",
    "hence we have all possible functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
